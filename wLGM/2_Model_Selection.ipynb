{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Model Selection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMULVg2PYBHGHPiRu7EnRb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovegohome/ML/blob/main/wLGM/2_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU2mMjsyTrUp"
      },
      "source": [
        "# Model Selection 모듈 소개\n",
        "\n",
        "## 학습/테스트 데이터 셋 분리 – train_test_split()\n",
        "\n",
        "### 사이킷런 model_selection 모듈의 주요 기능\n",
        "- 학습 데이터와 테스트 데이터 세트 분리\n",
        "- 교차 검증 분할 및 평가\n",
        "- Estimator의 하이퍼 파라미터 튜닝\n",
        "\n",
        "**학습 데이터와 테스트 데이터 세트 분리**\n",
        "- train_test_split() 함수 사용\n",
        "\n",
        "**학습 데이터 세트**\n",
        "- 머신러닝 알고리즘의 학습을 위해 사용\n",
        "- 데이터의 속성(피처)과 결정값(레이블) 모두 포함\n",
        "- 학습 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성과 결정값의 패턴을 인지하고 학습\n",
        "\n",
        "**테스트 데이터 세트** \n",
        "- 학습된 머신러닝 알고리즘 테스트용\n",
        "- 머신러닝 알고리즘은 제공된 속성 데이터를 기반으로 결정값 예측\n",
        "- 학습 데이터와 별도의 세트로 제공\n",
        "\n",
        "**train_test_split() 함수**\n",
        "\n",
        "train_test_split(feature_dataset, label_dataset, test_size, train_size, random_state, shuffle, stratify)\n",
        "\n",
        "\n",
        "- feature_dataset : 피처 데이터 세트\n",
        "    - 피처(feature)만으로 된 데이터(numpy) [5.1, 3.5, 1.4, 0.2],...\n",
        "- label_dataset : 레이블 데이터 세트\n",
        "    - 레이블(결정 값) 데이터(numpy) [0 0 0 ... 1 1 1 .... 2 2 2]\n",
        "- label_dataset : 테스트 데이터 세트 비율\n",
        "    - 전체 데이터 세트 중 테스트 데이터 세트 비율\n",
        "    - 지정하지 않으면 0.25\n",
        "- random_state : 세트를 섞을 때 해당 int 값을 보고 섞음\n",
        "    - 수행할 때마다 동일한 데이터 세트로 분리하기 위해 시드값 고정(실습용)\n",
        "    - 0 또는 4가 가장 많이 사용\n",
        "    - 하이퍼 파라미터 튜닝시 이 값을 고정해두고 튜닝해야 매번 데이터셋이 변경되는 것을 방지할 수 있음\n",
        "    \n",
        "- shuffle : 분할하기 전에 섞을지 지정\n",
        "    - default=True (보통은 default 값으로 놔둠)\n",
        "- stratify : 지정된 레이블의 클래스 비율에 맞게 분할\n",
        "    - default=None\n",
        "    - classification을 다룰 때 매우 중요한 옵션값\n",
        "    - stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train/ validation에 유지해 줌(한 쪽에 쏠려서 분배되는 것을 방지)\n",
        "    - 이 옵션을 지정해 주지 않고 classification 문제를 다룬다면, 성능의 차이가 많이 날 수 있음\n",
        "    \n",
        "   \n",
        "   \n",
        "예. train_test_split(iris_data, iris_label, test_size=0.3, random_state=11)\n",
        "\n",
        "\n",
        "train_test_split() 반환값\n",
        "* X_train : 학습용 피처 데이터 세트 (feature)\n",
        "* X_test : 테스트용 피처 데이터 세트 (feature)\n",
        "* y_train : 학습용 레이블 데이터 세트 (target)\n",
        "* y_test : 테스트용 레이블 데이터 세트 (target)\n",
        "* feature : 대문자 X_\n",
        "* label(target) : 소문자 y_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJou8fY6VGhQ"
      },
      "source": [
        "### (1) 학습/테스트 데이터 셋 분리하지 않고 예측\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zVF3sluToe8",
        "outputId": "9c1aa976-4f11-4185-af24-5755a4c09ace"
      },
      "source": [
        "# (1) 학습/테스트 데이터 셋 분리하지 않고 예측\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "train_data = iris_data.data\n",
        "train_label = iris_data.target\n",
        "\n",
        "# 학습 수행 \n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 테스트\n",
        "pred = dt_clf.predict(train_data)\n",
        "print(\"예측 정확도 : \", accuracy_score(train_label, pred))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도 :  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKV1-0IcVNBq"
      },
      "source": [
        "- 예측을 train_data로 했기 때문에 결과 1.0 (100%)으로 출력 (잘못됨)\n",
        "- 예측은 테스트 데이터로 해야 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf76o-ddVHMZ"
      },
      "source": [
        "### (2) 학습/테스트 데이터 셋 분리하고 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGoHn5aWUQFn"
      },
      "source": [
        "# (2) 학습/테스트 데이터 셋 분리하고 예측 \n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# 학습/테스트 분할(split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                test_size=0.2, random_state=4)\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuv0fQaYWJ_Z"
      },
      "source": [
        "# 학습 수행\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# 예측 수행\n",
        "pred = dt_clf.predict(X_test)\n",
        "print(\"예측 정확도 : \", accuracy_score(y_test, pred))\n",
        "\n",
        "# random_state=21 어떻게주느냐에 따라 예측 정확도가 조금씩 \n",
        "# 달라진다. \n",
        "# test_size=0.2 도 어떻게 주느냐에 따라 값이 달라짐\n",
        "# 손 맛 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB_0qox9WLg4"
      },
      "source": [
        "# 넘파이 ndarray 뿐만 아니라 판다스 DataFrame/Series도 train_test_split( )으로 분할 가능\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "iris_df = pd.DataFrame(iris_data.data, \n",
        "                       columns = iris_data.feature_names)\n",
        "iris_df['target'] = iris_data.target\n",
        "iris_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-awtSM8WM3g"
      },
      "source": [
        "# 피처 데이터프레임 반환(마지막 열 전까지, 마지막 열 제외)\n",
        "feature_df = iris_df.iloc[:, :-1]\n",
        "\n",
        "# 타겟 데이터프레임 반환\n",
        "target_df = iris_df.iloc[:, -1]\n",
        "\n",
        "# 학습 / 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, \n",
        "                                                    target_df,\n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=4)\n",
        "print(y_train)\n",
        "# 즉, 판다스로도 분할 되는 걸 확인함. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbyC_azLWPZm"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-hwu43oWQIw"
      },
      "source": [
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측정확도: {0: .3f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD0tlVWuWV2x"
      },
      "source": [
        "## Data Split과 모델 검증\n",
        "\n",
        "- 언제\n",
        "    - \"충분히 큰\" 데이터 세트를 가용할 때\n",
        "    - \"충분히 큰\" 데이터가 없을 때에는 교차 확인(Cross Validation) 고려\n",
        "    \n",
        "\n",
        "- 왜\n",
        "    - 학습에 사용되지 않은 데이터를 사용하여 예측을 수행함으로써 모델의 일반적인 성능에 대한 적절한 예측을 함\n",
        "    \n",
        "\n",
        "- 어떻게\n",
        "    - 홀드-아웃(Hold-out)\n",
        "    - 교차검증(Cross Validation,CV)\n",
        "    - 필요에 따라 Stratified Sampling\n",
        "\n",
        "### 홀드-아웃 방식\n",
        "- 데이터를 두 개 세트로 나누어 각각 Train과 Test 세트로 사용\n",
        "- Train과 Test의 비율을 7:3 ~ 9:1로 널리 사용하나, 알고리즘의 특성 및 상황에 따라 적절한 비율을 사용\n",
        "- Train – Validation - Test로 나누기도 함\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "https://algotrading101.com/learn/train-test-split-2/\n",
        "\n",
        "\n",
        "부적합한 데이터 선별로 인한 문제점\n",
        "- ML은 데이터에 기반하고, \n",
        "- 데이터는 이상치, 분포도, 다양한 속성값, 피처 중요도 등 \n",
        "- ML에 영향을 미치는 다양한 요소를 가지고 있음\n",
        "- 특정 ML 알고리즘에 최적으로 동작할 수 있도록\n",
        "- 데이터를 선별해서 학습한다면\n",
        "- 실제 데이터 양식과는 많은 차이가 있을 것이고\n",
        "- 결국 성능 저하로 이어질 것임\n",
        "\n",
        "문제점 개선 ---> 교차 검증을 이용해 더 다양한 학습 평가 수행\n",
        "\n",
        "### 교차검증(Cross Validation, CV)\n",
        "- k-fold Cross Validation이라고도 함\n",
        "- 전체 데이터 세트를 임의로 k개의 그룹으로 나누고, 그 가운데 하나의 그룹을 돌아가면서 테스트 데이터 세트로, 나머지 k-1개 그룹은 학습용 데이터 세트로 사용하는 방법\n",
        "- 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행\n",
        "\n",
        "\n",
        "- 사용 목적\n",
        "    - 데이터에 적합한 알고리즘인지 평가하기 위해 \n",
        "    - 모델에 적절한 hyperparameter 찾기 위해\n",
        "    - 과대적합 예방\n",
        "    - 데이터 편중을 막기 위해\n",
        "    \n",
        "\n",
        "    \n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "http://karlrosaen.com/ml/learning-log/2016-06-20/\n",
        "\n",
        "### 교차 검증 방법\n",
        "- K 폴드 교차 검증\n",
        "- Stratified K 폴드 교차 검증\n",
        "\n",
        "### K 폴드 교차 검증\n",
        "- K개의 데이터 폴드 세트를 만들어서\n",
        "- K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행\n",
        "- 가장 보편적으로 사용되는 교차 검증 기법\n",
        "\n",
        "\n",
        "- 5-폴드 교차 검증\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "**K 폴드 교차 검증 프로세스 구현을 위한 사이킷런 클래스**\n",
        "\n",
        "(1) KFold 클래스 : 폴드 세트로 분리하는 객체 생성\n",
        "- kfold = KFold(n_splits=5)\n",
        "\n",
        "(2) split() 메소드 : 폴드 데이터 세트로 분리\n",
        "- kfold.split(features)\n",
        "- 각 폴드마다  \n",
        "    학습용, 검증용, 테스트 데이터 추출  \n",
        "    학습용 및 예측 수행  \n",
        "    정확도 측정  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXSxPbDEWYPx"
      },
      "source": [
        "(3) 최종 평균 정확도 계산\n",
        "* K 폴드 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiF9nBrGWap5"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "\n",
        "#iris.shape \n",
        "#features.shape[0]\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ccRzFCRiZYN"
      },
      "source": [
        "# DecisionTreeClassifier 객체 생성 \n",
        "dr_clf = DecisionTreeClassifier(random_state=156)\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "# 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "cv_accuracy =  [] # 빈리스트 만들고 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbtaeylHiaj0"
      },
      "source": [
        "kfold.split(features) # 짠 나눠짐 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM1J1odkicMc"
      },
      "source": [
        "# 폴드 별 학습용, 검증용 데이터 세트의 행 인덱스 확인\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    print(train_index, test_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vhVefTZic7_"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train = label[train_index]\n",
        "    y_test = label[test_index]\n",
        "    \n",
        "    dt_clf.fit(X_train, y_train) # 학습\n",
        "    # 강사님 dr_clf로 객체 생성하신거같아요~??\n",
        "    pred = dt_clf.predict(X_test) # 앞에서 5번 나눈 거 대로\n",
        "    \n",
        "#    acc = accuracy_score(y_test, pred)\n",
        "    acc = np.round(accuracy_score(y_test, pred), 3) # 소수점 조절 \n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    \n",
        "    print('정확도: %f, 학습데이터 크기: %d, 검증데이터 크기: %d,' \n",
        "          %(acc, train_size, test_size))\n",
        "    cv_accuracy.append(acc) \n",
        "    \n",
        "print('평균 검증 정확도: ', np.mean(cv_accuracy).round(1))\n",
        "\n",
        "# 옴... cv_accuaracy\n",
        "# accuracy???\n",
        "# 왜 교수님은 0.9로 뜨는데 난 왜이렇게 길게 나오지..?\n",
        "\n",
        "# 데이터 세트가 어떻게 구성되느냐에 따라 다른 평균값이 나오기 때문에\n",
        "# 생기는 차이가 아닐까 합니다.\n",
        "# print('평균 검증 정확도 : ', np.mean(cv_accuracy).round(1))\n",
        "# 이렇게 바꾸시면 0.9\n",
        "# 위에서 round 처리 한 것은 acc의 값이지 \n",
        "# cv_accuracy의 값이 아니기 때문에 cv_accuracy의 출력에는 \n",
        "# 영향을 미치지 않습니다.\n",
        "\n",
        "# random_state가 모든 PC가 완벽히 같은 값을 뽑게 해주는게 아니라\n",
        "# 거의 같은 값을 뽑게 해주는거라서 차이가 있는 거다..?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56aY3MSCi2bX"
      },
      "source": [
        "### Stratified K 폴드 교차 검증\n",
        "- 불균형한 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식\n",
        "\n",
        "### 불균형한 데이터(imbalanced data) 문제\n",
        "- 관심 대상 데이터가 상대적으로 매우 적은 비율로 나타나는 데이터 문제\n",
        "\n",
        "- 분류 문제인 경우 : 클래스들이 균일하게 분포하지 않은 문제를 의미\n",
        "    - 예. 불량률이 1%인 생산라인에서 양품과 불량품을 예측하는 문제\n",
        "    - 사기감지탐지(fraud detection), 이상거래감지(anomaly detection), 의료진단(medical diagnosis) 등 에서 자주 나타남\n",
        "\n",
        "- 회귀 문제인 경우 : 극단값이 포함되어 있는 \"치우친\" 데이터 사례\n",
        "    - 예. 산불에 의한 피해 면적을 예측하는 문제\n",
        "    (https://www.kaggle.com/aleksandradeis/regression-addressing-extreme-rare-cases)\n",
        "\n",
        "\n",
        "**우회/극복하는 방법**\n",
        "- 데이터 추가 확보\n",
        "\n",
        "\n",
        "- Re-Sampling\n",
        "    - Under-sampling(과소표집)\n",
        "        - 다른 클래스에 비하여 상대적으로 많이 나타나는 클래스의 개수를 줄임\n",
        "        - 균형은 유지할 수 있으나 유용한 정보에 대한 손실이 있을 수 있음\n",
        "    - Over-Sampling(과대표집)\n",
        "        - 상대적으로 적게 나타나는 클래스의 데이터를 복제하여 데이터의 개수를 늘림\n",
        "        - 정보 손실은 없이 학습 성능은 높아지는 반면, 과적합의 위험이 있음\n",
        "        - 이를 회피하기 위해서 SMOTE 와 같이 임의의 값을 생성하여 추가하는 방법 사용\n",
        "        \n",
        "        \n",
        "![image.png](attachment:image.png)    \n",
        "\n",
        "* 먼저 K 폴드 문제점 확인하고, \n",
        "* 사이킷런의 Stratified K 폴드 교차 검증 방법으로 개선\n",
        "* 붓꽃 데이터 세트를 DataFrame으로 생성하고 \n",
        "* 레이블 값의 분포도 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilq2x4nxi36c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "irisf_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dmNSlJNic-i"
      },
      "source": [
        "iris_df['label'].value_counts()\n",
        "# 레이블 값은 0, 1, 2 값 모두 50개로 동일\n",
        "# 즉, Setosa, Versicolor, virginica 각 품종 50개 씩 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v66naivPidBB"
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "\n",
        "n = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n += 1 \n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print(\"[교차검증: %d]\" %(n))\n",
        "    print(\"  학습용 : \\n \", label_train.value_counts())\n",
        "    print(\"  검증용 : \\n \", label_test.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwvLsqsjidFQ"
      },
      "source": [
        "########## 참고 : 3개의 폴드 세트로 KFold 교차 검증 : 정확도 : 0 ###########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqam3nZ4idHZ"
      },
      "source": [
        "# DecisionTreeClassifier 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 3개의 폴드 세트로 분리하는 KFold 객체 생성\n",
        "kfold = KFold(n_splits=3)\n",
        "\n",
        "# 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "cv_accuracy = []\n",
        "\n",
        "n=0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n += 1 \n",
        "    \n",
        "    # 반복 시 마다 정확도 측정\n",
        "    acc = np.round(accuracy_score(y_test, pred), 3)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('%d \\n정확도: %f, 학습데이터크기: %d, 검증데이터: %d'\n",
        "         %(n, acc, train_size, test_size))\n",
        "    \n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도: ', np.mean(cv_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD2e4LCdidJ9"
      },
      "source": [
        "########## 참고 끝   ###########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW61IuZ7mL6u"
      },
      "source": [
        "- 위 코드 결과의 문제점\n",
        "    - 학습하지 않은 데이터를 검증 데이터로 사용\n",
        "    - 원할한 학습과 예측이 어려움\n",
        "    - 검증 정확도는 0\n",
        "\n",
        "StratifiedKFold 클래스\n",
        "- 원본 데이터의 레이블 분포를 고려한 뒤 이 분포와 동일하게 학습과 검증데이터 세트를 분배\n",
        "\n",
        "- KFold 사용법과 거의 비슷\n",
        "- 차이점\n",
        "  - 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에\n",
        "  - split() 메서드에 인자로 피처 데이터 세트뿐 아니라 \n",
        "  - 레이블 데이터 세트도 반드시 필요하다는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCswVPkkmKSp"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n=0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n = n + 1\n",
        "    \n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print(\"[교차검증 : %d]\" %n)\n",
        "    print('학습용 레이블 분포: \\n', label_train.value_counts())\n",
        "    print('검증용 레이블 분포: \\n', label_test.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4SnvF1GmKEr"
      },
      "source": [
        "# StratifiedfKFold를 이용해 붓꽃 데이터 교차 검증\n",
        "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
        "\n",
        "# 3개의 폴드 세트로 분리하는 StratifiedKFold 객체 생성\n",
        "skfold = StratifieldKFold(n_splits=3)\n",
        "\n",
        "# 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "cv_accuracy = []\n",
        "\n",
        "n=0\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    \n",
        "    # 반복 시 마다 정확도 측정\n",
        "    n += 1 \n",
        "    \n",
        "    acc = np.round(accuracy_score(y_test, pred), 3)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('%d \\n정확도: %f, 학습데이터: %d, 검증데이터크기: %d'\n",
        "         %(n, acc, train_size, test_size))\n",
        "    \n",
        "    cv_accuracy.append(acc)\n",
        "\n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도: ', np.mean(cv_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkVVRYJpkcf"
      },
      "source": [
        "Stratified K 폴드의 경우\n",
        "- 원본 데이터의 레이블 분포도 특성을 반영한 학습 및 검증 데이터 세트를 만들 수 있으므로\n",
        "- 왜곡된 레이블 데이터 세트에서는 반드시 Stratified K 폴드를 이용해서 교차 검증해야 함\n",
        "- 일반적으로 분류(Classification)에서의 교차 검증은 K 폴드가 아니라 Stratified K 폴드로 분할되어야 함\n",
        "- 회귀(Regression)에서는 Stratified K 폴드 지원되지 않음\n",
        "    - 이유 : 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에\n",
        "    - 결정값별로 분포를 정하는 의미가 없기 때문\n",
        "\n",
        "## 교차검증을 보다 간편하게 \n",
        "\n",
        "- 교차 검증 (Cross Validation) 과정\n",
        "    1. 폴드 세트 설정\n",
        "    2. for 문에서 반복적으로 학습 및 검증 데이터 추출 및 학습과 예측 수행\n",
        "    3. 폴드 세트별로 예측 성능을 평균하여 최종 성능 평가\n",
        "\n",
        "### cross_val_score( ) 함수\n",
        "- 1 ~ 3 단계의 교차 검증 과정을 한꺼번에 수행\n",
        "- 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation) 시켜주므로\n",
        "- 간단하게 교차 검증 수행 가능\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6ofTXBpmGD"
      },
      "source": [
        "### 붓꽃 자료를 3개 폴드로 분할하여 학습 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXIi16dsmHA5"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "features = iris.date\n",
        "label = iris.target\n",
        "\n",
        "scores = cross_val_score(dt_clf, features, label, scoring='accuracy'\n",
        "                        ,cv = 3)\n",
        "print('교차 검증별 정확도: ', scores)\n",
        "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5aYbcQ3qtbc"
      },
      "source": [
        "- cross_val_score()는 cv로 지정된 횟수만큼\n",
        "- scoring 파라미터로 지정된 평가 지표로 평가 결과값을 배열로 반환\n",
        "- 일반적으로 평가 결과값 평균을 평가 수치로 사용\n",
        "\n",
        "## 교차 검증과 최적의 하이퍼파라미터 튜닝을 한번에\n",
        "\n",
        "하이퍼파라미터(Hyper parameter)\n",
        "- 머신러닝 알고리즘을 구성하는 요소\n",
        "- 이 값들을 조정해 알고리즘의 예측 성능을 개선할 수 있음\n",
        "\n",
        "### 사이킷런의 GridSearchCV클래스\n",
        "\n",
        "- Classifier나 Regressor와 같은 알고리즘에 사용되는\n",
        "- 하이퍼 파라미터를 순차적으로 입력하면서\n",
        "- 최적의 파라미터를 편리하게 도출할 수 있는 방법 제공  \n",
        "-(Grid는 격자라는 의미 : 촘촘하게 파라미터를 입력하면서 테스트 하는 방식)\n",
        "\n",
        "즉,  \n",
        "- 머신러닝 알고리즘의 여러 하이퍼 파라미터를  \n",
        "- 순차적으로 변경하면서 최고 성능을 가지는 파라미터를 찾고자 한다면  \n",
        "- 파라미터의 집합을 만들어 순차적으로 적용하면서 최적화 수행  \n",
        "\n",
        "**GridSearchCV 클래스 생성자의 주요 파라미터**\n",
        "\n",
        "- estimator : classifier, regressor, peipeline\n",
        "\n",
        "\n",
        "- param_grid : key + 리스트 값을 가지는 딕셔너리 (estimator 튜닝을 위한 하이퍼 파라미터 )\n",
        "     - key: 파라미터명, 리스트값:파라미터 값\n",
        "     \n",
        "     \n",
        "- scoring : 예측 성능을 측정할 평가 방법 \n",
        "     - 성능 평가 지표를 지정하는 문자열\n",
        "     - 예: 정확도인 경우 'accuracy'\n",
        "     \n",
        "     \n",
        "- cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수\n",
        "\n",
        "\n",
        "- refit : 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습 여부\n",
        "     - 디폴트 : True    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xbaGTx5idMD"
      },
      "source": [
        "# GridSearchCV를 이용해\n",
        "# 결정 트리 알고리즘의 여러 가지 최적화 파라미터를 순차적으로 적용해서\n",
        "# 붓꽃 데이터 예측 분석\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data,\n",
        "                                                   iris.target,\n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state=121)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "parameters = {'max_depth': [1,2,3], 'min_samples_split': [2,3]}\n",
        "# 하이퍼파라미터는 딕셔너리 형식으로 지정\n",
        "# key : 결정트리의 하이파라미터\n",
        "# value : 하이퍼파라미터의 값"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYephMnEr489"
      },
      "source": [
        "min_samples_split : 자식 규칙 노드를 분할해서 만드는데 필요한 최소 샘플 데이터 개수\n",
        "- min_samples_split=4로 설정하는 경우\n",
        "    - 최소 샘플 개수가 4개 필요한데\n",
        "    - 3개만 있는 경우에는 더 이상 자식 규칙 노드를 위한 분할을 하지 않음\n",
        "\n",
        "\n",
        "트리 깊이도 줄어서 더 간결한 결정 트리 생성\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8heteX0dr6DF"
      },
      "source": [
        "grid_tree = GridSearchCV(dt_clf, param_grid=parameters, cv=3, \n",
        "                         refit=True, return_train_score=True)\n",
        "grid_tree.fit(X_train, y_train)\n",
        "\n",
        "scores_df = pd.DataFrame(grid_tree.cv_results_)\n",
        "scores_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qX7OsjSidOW"
      },
      "source": [
        "# 파라미터 확인\n",
        "grid_tree.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_QpHUk8idRO"
      },
      "source": [
        "# GridSearchCV 결과 세트로 딕셔너리 형태인 cv_results_를 \n",
        "# DataFrame으로 변환 후 일부 파라미터 확인 \n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74cW0x8YidSh"
      },
      "source": [
        "# 최고 성능을 가지는 파라미터 조합 및 예측 성능 1위 값 출력\n",
        "print('최적 파라미터: ', grid_tree.best_params_)\n",
        "print('최고 정확도: ', grid_tree.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_QaqB4LidVE"
      },
      "source": [
        "# GridSearchCV 객체의 생성 파라미터로 refit = True로 설정된 경우(디폴트)\n",
        "# GridSearchCV가 최적 성능을 나타내는 하이퍼 파리미터로 Estimator를 학습하고\n",
        "# best_estimator_ 로 저장\n",
        "# (GridSearchCV의 refit으로 이미 학습이 된 estimator)\n",
        "best_dt = grid_tree.best_estimator_\n",
        "\n",
        "# best_estimator_는 이미 최적 학습이 됐으므로 별도 학습 필요 없이\n",
        "# 바로 예측 가능\n",
        "\n",
        "pred = best_dt.predict(X_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axslYnKuuEPA"
      },
      "source": [
        "**일반적인 머신러닝 모델 적용 방법**\n",
        "\n",
        "- 일반적으로 학습 데이터를 GridSearchCV를 이용해\n",
        "- 최적 하이퍼 파라미터 튜닝을 수행한 뒤에\n",
        "- 별도의 테스트 세트에서 이를 평가하는 방식"
      ]
    }
  ]
}