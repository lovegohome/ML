{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d14c451-2883-41b9-b553-f6a8609a8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd37351-fe8f-4fcc-83d9-e1d088a6a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('./titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584e1b44-1c53-4eb5-b11d-750a5eefa136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4d9d84-2879-4e2f-890e-79a239c6bdc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5666d040e152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtitanic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtitanic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5666d040e152>\u001b[0m in \u001b[0;36mencode_features\u001b[1;34m(dataDF)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mdataDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[0;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[1;32m--> 117\u001b[1;33m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[0;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf18766-cc96-48fc-96f7-501810d38f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-240f0ceda4b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtitanic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mtitanic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-240f0ceda4b6>\u001b[0m in \u001b[0;36mencode_features\u001b[1;34m(dataDF)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mdataDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[0;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[1;32m--> 117\u001b[1;33m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[0;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "# 문자열 카테고리 피처를 숫자형 카테고리 피처로 변환\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 레이블 인코딩 함수\n",
    "def encode_features(dataDF):\n",
    "    # 문자열 카테고리 피처\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288daef5-27c5-45ba-9132-fee2b3dfafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace = True)\n",
    "# 원데이터 변환 \n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070fd93-e0d8-4403-b1d1-f1800e98a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[Feature])\n",
    "        df[feature] = le.transform(df[featrue])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc87d7a-fa4a-43ee-94ab-cb07db734b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('./titanic_csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f339f-4f14-4ec5-b4be-58a4c43b7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_titanic_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4c11b-59c3-4f99-894d-2c71534e6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df\n",
    "                                                   test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e94f800-c9ef-466b-8538-caf2564b1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 결정트리, 랜덤포레스트, 로지스틱회귀를 위한 estimator 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 결정트리 학습/예측/평가\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('결정 트리정확: {0:.4f}'. format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# 랜덤포레스트 학습/예측/평가\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('랜덤포레스트 정확도: {0:.4f}'. format(accuracy_score(y_test, rf_pred)))\n",
    "# 랜덤이 좋게 나왔나요? \n",
    "\n",
    "# 로지스틱회귀 학습/예측/평가\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = dt_clf.predict(X_test)\n",
    "print('로지스틱회귀 정확도: {0:.4f}'. format(accuracy_score(y_test, lr_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95735adb-779e-4954-a636-3afc8a5ad7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "#    kfold.split(X_titanic_df)\n",
    "    for iter_n, train_index, test_index in enumerate(kfold.split(X_titanic_df)):\n",
    "        # enumerate 열과 행 붙이면서 index 붙여준다. \n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(y_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        scores.append[accuracy]\n",
    "        print('교차검증 %d : %f' %(iter_n, accuracy))\n",
    "        \n",
    "    mean_accuracy = np.mean(scores)\n",
    "    print('평균 정확도: %f' % mean_accuracy)\n",
    "    \n",
    "exec_fold(dt_clf, folsd=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f6517-4fa4-4ce3-b4df-6381cff1de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcfa5d-a723-430e-a316-8fb02a53c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b3379-ed84-477f-a170-62adbf65c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kfold.split(X_titanic_df):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764686df-4717-4822-9a55-c8e265ee2cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52742e95-2730-4ea1-92e2-c87b92617278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e9a39-97ff-4980-bbb5-8c2fb2ed3fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08ab2e-01dd-4a98-874b-f3bdc6b377db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25c874-b386-461b-977d-2e02bed02e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bc86e-009a-415e-84f2-9f3779e78609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe5faf-6070-4222-b2ae-3ae4c39ae24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_n, accuracy in enumerate(scores):\n",
    "    print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_n, accuracy))\n",
    "    \n",
    "print('평균 정확도: {0:.4f}'.formnat(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc233bda-df75-4bad-b1e6-648cdc279b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth': [2,3,5,10],\n",
    "             'min_samples_split': [2,3,5],\n",
    "             'min_samples_leaf': [1,5,8]}\n",
    "grid_dclf = GridSearchCV(df_clf, param_grid = parameters, scoring = 'accuracy', cv=5)\n",
    "grid_sclf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터 : ', grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "sccuracy = accuracy_score(y_test, dpredictions)\n",
    "print('테스트 세트에서의 DescisionTreeClassifier 정확도: {0:.4f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2ebcf-fb8b-452f-96e5-d4cb6558770f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6dfe1b-c38c-4cba-8645-7073403b99a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779daf6-4df9-49d6-8a2d-5afc0ff5683a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5338d4-c4aa-4d72-b76d-3df933a58f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7912e-a1fc-4482-a2f1-caad49ebc703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085006a6-938a-4fde-9f6f-3bb33d59919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1: #비교 vs assign\n",
    "                pred[i]=0\n",
    "            else\n",
    "                pred[i]=1\n",
    "        return pred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31e60f-e2ac-45d6-88bf-b291dfb139eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ????????????????????\n",
    "\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean, inplace=True)\n",
    "titanic_df['Cabin'].fillna(\"N\", inplace = True)\n",
    "titanic_df['Embarked'].fillna('N', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129a677-46c4-4036-a1ff-c17f9980909e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_df = pd.read_\n",
    "\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "mypred = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7e975-aa39-48df-85ce-1b236849c520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a3f9d-4747-43ff-a670-f64037ed48ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469ae36-0c92-4250-ae23-6a6412aee9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b62c26-9535-4cda-8b17-d961971cd102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e2649-dba6-41ec-b7aa-e3a445e1f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "548f0206-9e03-4fdc-b2d9-b2c45fed9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(set, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17923a70-61a1-4876-b484-8570753ac444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "255e5755-2c64-48db-8ba0-4888e5066b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape\n",
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de0d9dd3-ee2b-4500-82cd-cb5c13a54a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target\n",
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2c46ef3-b200-4196-9076-7f0101ee7e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (digits.target == 7).astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b12f15e-5ad4-4d36-8888-da21ce4c268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y,\n",
    "                                                   random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59cbb589-550a-426b-89d4-e0d594a3ff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  3., ..., 12., 14.,  7.],\n",
       "       [ 0.,  1.,  9., ..., 10.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ..., 16., 13.,  1.],\n",
       "       [ 0.,  1., 11., ..., 13., 16.,  5.],\n",
       "       [ 0.,  0.,  6., ...,  6.,  0.,  0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "062c0082-6b7b-4091-8b1d-7a4daed20174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  7., ...,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  1., 13., ..., 15.,  3.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 12.,  0.,  0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed474d2f-12c2-4468-8eef-79247864176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3390b82-962f-4a86-b6bd-bc3e398d43a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "465bd054-183c-472d-9911-f060f6a11549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test.shape :  (450,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    405\n",
       "1     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('y_test.shape : ', y_test.shape)\n",
    "pd.Series(y_test).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98d7480b-ccf6-4e59-804b-736816e1184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "fake_cl = MyFakeClassifier()\n",
    "\n",
    "fake_cl.fit(X_train, y_train)\n",
    "fake_Pred = fake_cl.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, fake_Pred)\n",
    "print('정확도 : ', np.round((accuracy), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d0287-252c-465b-b010-0c4e7cdf18d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db15fc4-32e6-4f90-a77f-43f65947f64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1dc8cb2d-206c-4c4f-9604-323fe9ed2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# MNIST의 fakepred\n",
    "\n",
    "confusion_matrix(y_test, fake_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd81f549-2541-43a4-875b-07de5342ef42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1b49b-82f3-4f2d-84b2-1d7ca261d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88ceeb-788e-4b22-a044-7dc1373a9b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adac703-3955-47f1-bf6c-ed1327e7c924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d6205ac-6bda-44c7-b5b6-a258cb588f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(set, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "\n",
    "digits = load_digits()\n",
    "y =(digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, \n",
    "                                                    random_state=11)\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9de6dbd-80cd-411b-9b67-52b51a067f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakepred.astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b226a717-4ea0-4d7d-b02e-03c56822a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\multi2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print('정밀도:', precision_score(y_test, fakepred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7b60f7e-c9a3-461d-8a42-e985bc5ad87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred) #오차행렬\n",
    "    accuracy = accuracy_score(y_test, pred)    #\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.3f}, 정밀도: {0:.3f}'.format(accuracy, precision, recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99356e-c8e1-4341-b4ce-21e643fc10c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259c9c8-4985-4e21-a682-5b6e15281dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0cbc4-9b4a-49ef-8836-4e6180f1b1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7130860-b7eb-4adb-b4d5-a8bbb1e64fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663f95e-6eaf-4dfc-a403-f0e33f1ef8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee862871-acea-490b-94f6-ac7da0c48a76",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-4b3671fb9b20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_clf' is not defined"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa654502-577c-4244-b861-e06fcbed18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65cd03-d3e6-47ea-ba3f-991b80eeca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측')\n",
    "print(pred_proba_result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0133c529-bbeb-4732-bb68-dda7858013c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1,-1,-2],\n",
    "    [2,0,0],\n",
    "    [0,1.1,1.2]]\n",
    "\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d75f62-58e3-458f-a980-0caa936c672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "c_threshold =0.5\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "bina = Binarizer(threshold=c_threshold).fit(pred_proba_1)\n",
    "custom_predict = bina.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da923f-e462-422f-b542-d4cb0757c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_threshold =0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "bina = Binarizer(threshold=c_threshold).fit(pred_proba_1)\n",
    "custom_predict = bina.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4047cb3-b8e0-40f6-81ac-02591a60082f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e2d10-ff72-4308-9258-f7c847754454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac447f36-408b-4c24-9d86-be65197a4f9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-df64a8d31df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred_proba_class1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m precision, recalls, thresholds = precision_recall_curve(y_test,\n\u001b[0;32m      5\u001b[0m                                                        pred_proba_class1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "precision, recalls, thresholds = precision_recall_curve(y_test,\n",
    "                                                       pred_proba_class1)\n",
    "print('임계값 shape: ', thresholds.shape)\n",
    "print('정밀도 shape: ', precisions.shape)\n",
    "print('재현율 shape: ', recalls.shape)\n",
    "\n",
    "idx = np.arange(0, thresholds.shape[0], 15)\n",
    "print('sample index: ', idx)\n",
    "print('임계값 sample: ', thresholds[idx])\n",
    "print('정밀도 sample: ', precisions[idx])\n",
    "print('재현율 sample: ', recalls[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce416fd-792a-4da1-9feb-dfb4959795a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('임계값 sample: ', thresholds[idx], 3)\n",
    "print('정밀도 sample: ', precisions[idx], 3)\n",
    "print('재현율 sample: ', recalls[idx], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd0cbe-f5c8-4808-9d80-374c3feb81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test,\n",
    "                                                            pred_proba_c1)\n",
    "    plt.figure(figsize = (8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle ='--', \n",
    "            label = 'precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    plt.xlabel('Threshold value'): plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(): plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e501a8-2d9b-4964-bf0d-d565b3359f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216de49-2bd9-4ab8-8d3d-d176d678d7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a80bf0f9-dc12-419f-b789-493570be0d3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-101-9e4182812b89>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-101-9e4182812b89>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from sklearn.metrics\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93656e-a8ab-4e62-a08a-f0872d13dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = aonfusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    \n",
    "    f1=f1_score(y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'\n",
    "         .format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0e271-0e3c-4a4c-a26d-7837b2fb8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:.1], reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc353e99-c8b2-4c10-a0bd-1e6185eedc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb101e-95eb-4e0a-980d-b8754c75984e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1561ba-f7c2-4d07-9a98-e49155f17d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0b755-db10-4e7d-804e-197ffc8adb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열 의 index: ', thr_index)\n",
    "print('샘플용 임곗값: ', np.round(thresholds[thr_index],2))\n",
    "\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31b60f-b63c-4eff-aa90-64586eb896bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed86c6-401a-4a29-9c67-f1f5bdab5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test, pred_proba_c1):\n",
    "    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.plot(fprs, tprd, label='ROC')\n",
    "    plt.plot([0,1],[0,1], 'k--', label='Random' )\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736d0fb-3499-4e77-bbf8-c36e0534ca7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cbfa6-3595-4fb2-a7b1-f853864acce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de60b0-b093-42a3-a6ed-3e8fb32043b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8062d3-6dfa-4c66-b2bb-b907aeac64d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f990e-b74b-4738-8678-adc7a71f67f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abafa9-82c3-4f3a-ad42-e9717f7616c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e3cf8-b0d5-4eee-a107-cb81ddc607bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609a712-b8ab-4a4e-b8a6-da0432a63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = aonfusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    \n",
    "    f1=f1_score(y_test, pred)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'\n",
    "         .format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf26ac1-f038-4d65-be4b-b9bbf9cb3535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175883c-a670-4ad1-b71a-18c828be184f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi2",
   "language": "python",
   "name": "multi2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
